{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busca de √çndice e Consulta de documento\n",
    "\n",
    "**Autor:** Davi J. Leite Santos  \n",
    "**Vers√£o:** 0.0.3  \n",
    "**Data:** 25 de Abril de 2024  \n",
    "**Localiza√ß√£o:** Ribeir√£o das Neves, Minas Gerais - Brasil  \n",
    "\n",
    "## Contato\n",
    "- üè† **Endere√ßo:** Ribeir√£o das Neves, Minas Gerais - Brasil\n",
    "- üìß **Email:** davi.jls@outlook.com\n",
    "- üåê **LinkedIn:** davi-j-leite-santos\n",
    "- üåê **Website:** davijls.com.br\n",
    "\n",
    "## Principais Compet√™ncias\n",
    "- **Ciberseguran√ßa**\n",
    "- **Seguran√ßa da Informa√ß√£o**\n",
    "- **Opera√ß√µes de TI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun√ß√£o de ranqueamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar um sistema de ranqueamento eficiente e matematicamente robusto, uma boa escolha √© o modelo de Recupera√ß√£o de Informa√ß√£o Vetorial, que utiliza o c√°lculo de similaridade de cosseno entre os vetores de termo-documento e o vetor de termos da consulta. Essa abordagem √© eficiente e amplamente utilizada em sistemas de recupera√ß√£o de informa√ß√µes.\n",
    "\n",
    "## Fun√ß√µes Matem√°ticas do Modelo Vetorial\n",
    "\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency):\n",
    "\n",
    "- TF (Term Frequency): Frequ√™ncia de um termo em um documento.\n",
    "- IDF (Inverse Document Frequency): Medida de quanto um termo √© raro em todos os documentos.\n",
    "\n",
    "## Similaridade de Cosseno:\n",
    "\n",
    "Medida de similaridade entre dois vetores que quantifica a similaridade entre eles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobre o codigo\n",
    "\n",
    "Este c√≥digo fornece uma implementa√ß√£o de um sistema de ranking de documentos usando t√©cnicas de recupera√ß√£o de informa√ß√µes baseadas em modelos vetoriais, como TF-IDF (Term Frequency-Inverse Document Frequency) e similaridade de cosseno. Essa abordagem √© bastante utilizada para determinar a relev√¢ncia de documentos com base em uma consulta fornecida pelo usu√°rio. Aqui est√° uma descri√ß√£o detalhada de cada componente e funcionalidade chave do c√≥digo:\n",
    "\n",
    "### Componentes Principais do C√≥digo\n",
    "\n",
    "#### 1. **Configura√ß√µes e Bibliotecas**\n",
    "- O c√≥digo utiliza bibliotecas como `re`, `nltk`, `sklearn`, e `json` para realizar limpeza de texto, processamento de linguagem natural e manipula√ß√£o de dados.\n",
    "- Configura√ß√£o de stopwords e stemmer em portugu√™s para preparar os dados textualmente.\n",
    "\n",
    "#### 2. **Fun√ß√µes de Limpeza e Preprocessamento de Texto**\n",
    "- **clean_text**: Limpa o texto removendo caracteres especiais e convertendo tudo para min√∫sculas. Stopwords s√£o tamb√©m removidas para reduzir ru√≠dos nos dados.\n",
    "- **apply_stemming**: Aplica redu√ß√£o das palavras aos seus radicais, utilizando `RSLPStemmer`.\n",
    "- **preprocess_query**: Combina as fun√ß√µes de limpeza e stemming para preparar consultas de busca.\n",
    "\n",
    "#### 3. **Carregamento de Dados**\n",
    "- **load_data**: Carrega os arquivos de vocabul√°rio e √≠ndice geral, que cont√™m informa√ß√µes preparadas para o processamento de textos e consulta.\n",
    "- **load_document**: Carrega e processa documentos de um caminho especificado, aplicando limpeza e stemming.\n",
    "\n",
    "#### 4. **Fun√ß√µes para Carregamento e Prepara√ß√£o de Documentos**\n",
    "- **get_documents**: Itera sobre o √≠ndice geral para extrair documentos e seus identificadores, que s√£o essenciais para a recupera√ß√£o de informa√ß√µes durante a busca.\n",
    "\n",
    "#### 5. **C√°lculo do TF-IDF e Busca**\n",
    "- **search_query_tfidf**: Utiliza o `TfidfVectorizer` da biblioteca `sklearn` para transformar documentos e consultas em representa√ß√µes de TF-IDF, e ent√£o calcula a similaridade de cosseno para determinar a relev√¢ncia dos documentos em rela√ß√£o √† consulta.\n",
    "\n",
    "#### 6. **Exibi√ß√£o dos Resultados**\n",
    "- **display_results_with_scores**: Organiza e exibe os resultados da busca, mostrando os documentos com suas pontua√ß√µes. Os documentos s√£o exibidos em ordem de relev√¢ncia com o tempo de busca registrado.\n",
    "\n",
    "### Uso e Benef√≠cios\n",
    "Este c√≥digo √© ideal para sistemas onde a precis√£o e a relev√¢ncia da informa√ß√£o recuperada s√£o cruciais, como em sistemas de busca internos de empresas ou aplica√ß√µes acad√™micas onde documentos precisam ser recuperados com base em seu conte√∫do sem√¢ntico. A capacidade de processar e indexar grandes conjuntos de dados de texto e realizar buscas r√°pidas e eficientes s√£o pontos-chave deste sistema.\n",
    "\n",
    "### Exemplo de Uso\n",
    "No exemplo de c√≥digo, uma consulta √© pr√©-processada e uma busca TF-IDF √© realizada nos documentos carregados. Os resultados s√£o ent√£o exibidos com pontua√ß√µes de relev√¢ncia, demonstrando a efic√°cia do sistema em encontrar e classificar documentos com base na consulta do usu√°rio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\davim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\davim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\davim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"rslp\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"portuguese\"))\n",
    "stemmer = RSLPStemmer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√µes de Limpeza e Preprocessamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)  # Remove special characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "def apply_stemming(text):\n",
    "    tokens = nltk.word_tokenize(text, language=\"portuguese\")\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return \" \".join(stemmed_tokens)\n",
    "\n",
    "\n",
    "def preprocess_query(query):\n",
    "    cleaned_query = clean_text(query)\n",
    "    stemmed_query = apply_stemming(cleaned_query)\n",
    "    return stemmed_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def load_document(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "    cleaned_text = clean_text(text)\n",
    "    stemmed_text = apply_stemming(cleaned_text)\n",
    "    return stemmed_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar Dados e Preparar Documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(vocab_geral_file, index_geral_file):\n",
    "    with open(vocab_geral_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        vocab_geral = json.load(f)\n",
    "    with open(index_geral_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        index_geral = json.load(f)\n",
    "    return vocab_geral, index_geral\n",
    "\n",
    "\n",
    "vocab_geral_file = \"cleaned_vocab_geral.json\"\n",
    "index_geral_file = \"cleaned_index_geral.json\"\n",
    "\n",
    "vocab_geral, index_geral = load_data(vocab_geral_file, index_geral_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading documents: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6781155/6781155 [00:12<00:00, 526978.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_documents(index_geral):\n",
    "    documents = []\n",
    "    doc_ids = []\n",
    "    for word_id, data in tqdm(index_geral.items(), desc=\"Loading documents\"):\n",
    "        for doc_id in data[\"doc_info\"]:\n",
    "            doc_ids.append(doc_id)\n",
    "            documents.append(data[\"file_names\"][0])\n",
    "    return documents, doc_ids\n",
    "\n",
    "\n",
    "documents, doc_ids = get_documents(index_geral)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√µes para o calculo do TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query_tfidf(query, documents):\n",
    "    start_time = time.time()\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "    query_vector = vectorizer.transform([query])\n",
    "\n",
    "    scores = (tfidf_matrix * query_vector.T).toarray().flatten()\n",
    "\n",
    "    # Adicionar barra de progresso\n",
    "    sorted_scores_idx = tqdm(\n",
    "        scores.argsort()[::-1], desc=\"Calculating Scores\", unit=\"doc\"\n",
    "    )\n",
    "\n",
    "    sorted_scores = [\n",
    "        (documents[i], scores[i]) for i in sorted_scores_idx if scores[i] > 0\n",
    "    ]\n",
    "\n",
    "    end_time = time.time()\n",
    "    search_time = end_time - start_time\n",
    "\n",
    "    return list(set(sorted_scores)), search_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando todas as fun√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_with_scores(sorted_scores, search_time):\n",
    "    print(f\"{'Site':<200}{'Score':<110}\")\n",
    "    print(\"=\" * 210)\n",
    "    for file_name, score in sorted_scores:\n",
    "        print(f\"{file_name:<200}{score:<110.4f}\")\n",
    "\n",
    "    print(f\"\\nSearch completed in {search_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso\n",
    "query = \"buceta cu vagina anal sexo toy pussy pinto dick desgra√ßa tnc fuder sefuder fdp bunda\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Scores: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9048738/9048738 [00:05<00:00, 1553536.13doc/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Results:\n",
      "Site                                                                                                                                                                                                    Score                                                                                                         \n",
      "==================================================================================================================================================================================================================\n",
      "www_metropoles_com]celebridades]deborah-secco-admite-que-ama-sexo-anal-e-nunca-cuspiu-gozo-veja-video.txt                                                                                               0.2045                                                                                                        \n",
      "www_metropoles_com]colunas]pouca-vergonha]bifobia-e-falocentrismo-o-que-envelheceu-mal-em-sex-and-the-city.txt                                                                                          0.2454                                                                                                        \n",
      "www_metropoles_com]colunas]pouca-vergonha]beijo-grego-44-das-pessoas-ja-gozaram-com-o-carinho-anal-veja-dicas.txt                                                                                       0.2063                                                                                                        \n",
      "\n",
      "Search completed in 107.22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Search\n",
    "preprocessed_query = preprocess_query(query)\n",
    "sorted_scores_tfidf, search_time_tfidf = search_query_tfidf(\n",
    "    preprocessed_query, documents\n",
    ")\n",
    "\n",
    "print(\"TF-IDF Results:\")\n",
    "display_results_with_scores(sorted_scores_tfidf, search_time_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
