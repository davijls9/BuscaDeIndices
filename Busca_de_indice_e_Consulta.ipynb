{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busca de √çndice e Consulta de documento\n",
    "\n",
    "**Autor:** Davi J. Leite Santos  \n",
    "**Vers√£o:** 0.0.3  \n",
    "**Data:** 25 de Abril de 2024  \n",
    "**Localiza√ß√£o:** Ribeir√£o das Neves, Minas Gerais - Brasil  \n",
    "\n",
    "## Contato\n",
    "- üè† **Endere√ßo:** Ribeir√£o das Neves, Minas Gerais - Brasil\n",
    "- üìß **Email:** davi.jls@outlook.com\n",
    "- üåê **LinkedIn:** davi-j-leite-santos\n",
    "- üåê **Website:** davijls.com.br\n",
    "\n",
    "## Principais Compet√™ncias\n",
    "- **Ciberseguran√ßa**\n",
    "- **Seguran√ßa da Informa√ß√£o**\n",
    "- **Opera√ß√µes de TI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobre o codigo\n",
    "\n",
    "## Cabe√ßalho e Metadados\n",
    "O cabe√ßalho inicial identifica o autor, a vers√£o, a data e o local de cria√ß√£o do c√≥digo, al√©m de detalhes de contato e compet√™ncias principais, que incluem Ciberseguran√ßa, Seguran√ßa da Informa√ß√£o e Opera√ß√µes de TI.\n",
    "\n",
    "## Dicion√°rios de Vocabul√°rio\n",
    "Dois dicion√°rios, VOCAB e VOCAB2, s√£o definidos para associar palavras-chave a √≠ndices num√©ricos. Esses vocabul√°rios s√£o essenciais para mapear termos a seus respectivos √≠ndices em opera√ß√µes de indexa√ß√£o e busca.\n",
    "\n",
    "## Estruturas de Dados Iniciais\n",
    "O c√≥digo define array como um dicion√°rio que organiza √≠ndices de documentos e as posi√ß√µes de palavras dentro deles. Este dicion√°rio √© ent√£o transformado em uma lista de tuplas chamada ii2, que facilita o manuseio dos dados.\n",
    "\n",
    "## Fun√ß√µes de Reconstru√ß√£o de Documentos\n",
    "V√°rias fun√ß√µes (reconstruir_documento, reconstruir_documento2, reconstruir_documento3) s√£o implementadas para converter os √≠ndices armazenados de volta em formato leg√≠vel, demonstrando como as palavras est√£o organizadas nos documentos.\n",
    "\n",
    "## Indexa√ß√£o de Novos Documentos\n",
    "O c√≥digo segue com uma simula√ß√£o de indexa√ß√£o de novos documentos atrav√©s de um processo que envolve a divis√£o de textos em palavras, limpeza de pontua√ß√µes e convers√£o para min√∫sculas, al√©m de atualizar o vocabul√°rio e √≠ndices invertidos com novas palavras.\n",
    "\n",
    "## Consulta Usando √Årvore Sint√°tica\n",
    "Uma funcionalidade de consulta utilizando uma √°rvore de operadores l√≥gicos (AND, OR) √© desenvolvida, permitindo a realiza√ß√£o de buscas complexas por meio de combina√ß√µes de termos.\n",
    "\n",
    "## Compress√£o de Texto\n",
    "A parte final do c√≥digo aborda duas t√©cnicas de compress√£o de texto: a compress√£o usando o m√©todo de Huffman, que cria uma √°rvore de frequ√™ncia das palavras para gerar c√≥digos de compress√£o eficientes, e a compress√£o baseada em dicion√°rio, que substitui palavras por tokens definidos manualmente para reduzir o tamanho do texto.\n",
    "\n",
    "Cada parte do c√≥digo √© minuciosamente explicada por meio de coment√°rios e divis√µes l√≥gicas, facilitando a compreens√£o das opera√ß√µes realizadas e de como cada componente contribui para o processamento de texto e recupera√ß√£o de informa√ß√µes. O uso de tabelas e formatos de impress√£o amig√°veis (como prettytable) melhora a visualiza√ß√£o dos resultados, tornando as sa√≠das mais leg√≠veis para an√°lise ou demonstra√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processo de carregar os arquivos e guarda-los\n",
    "\n",
    "Essa parte server para acessar cada documento e fazer o indice invertido de cada um, justamente para armazena-los de alguma forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = {\n",
    "    \"boa\": (0),\n",
    "    \"noite\": (1),\n",
    "    \"pessoal\": (2),\n",
    "    \"ja\": (3),\n",
    "    \"comecem\": (4),\n",
    "    \"0\": (5),\n",
    "    \"projeto\": (6),\n",
    "    \"alguma\": (7),\n",
    "    \"duvida\": (8),\n",
    "    \"isso\": (9),\n",
    "    \"e\": (10),\n",
    "    \"tudo\": (11),\n",
    "}\n",
    "\n",
    "\n",
    "VOCAB2 = {\n",
    "    \"cada\": 0,\n",
    "    \"qual\": 1,\n",
    "    \"sabe\": 2,\n",
    "    \"amar\": 3,\n",
    "    \"a\": 4,\n",
    "    \"seu\": 5,\n",
    "    \"modo\": 6,\n",
    "    \"o\": 7,\n",
    "    \"pouco\": 8,\n",
    "    \"importa\": 9,\n",
    "    \"essencial\": 10,\n",
    "    \"e\": 11,\n",
    "    \"que\": 12,\n",
    "    \"saiba\": 13,\n",
    "    \"boa\": 14,\n",
    "    \"prova\": 15,\n",
    "    \"todos\": 16,\n",
    "    \"nao\": 17,\n",
    "    \"quero\": 18,\n",
    "    \"ter\": 19,\n",
    "    \"terrivel\": 20,\n",
    "    \"limitacao\": 21,\n",
    "    \"de\": 22,\n",
    "    \"quem\": 23,\n",
    "    \"vive\": 24,\n",
    "    \"apenas\": 25,\n",
    "    \"do\": 26,\n",
    "    \"passivel\": 27,\n",
    "    \"fazer\": 28,\n",
    "    \"sentido\": 29,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, [0])\n",
      "(1, 0, [1])\n",
      "(2, 0, [2])\n",
      "(3, 0, [3, 16])\n",
      "(4, 0, [4])\n",
      "(4, 1, [2])\n",
      "(4, 2, [3])\n",
      "(5, 0, [5])\n",
      "(6, 0, [6, 8])\n",
      "(7, 0, [7, 11])\n",
      "(8, 0, [9])\n",
      "(9, 0, [10])\n",
      "(10, 0, [12])\n",
      "(11, 0, [13])\n",
      "(11, 2, [12])\n",
      "(12, 0, [14])\n",
      "(12, 2, [11])\n",
      "(13, 0, [15])\n",
      "(14, 1, [0])\n",
      "(15, 1, [1])\n",
      "(16, 1, [3])\n",
      "(17, 2, [0])\n",
      "(18, 2, [1])\n",
      "(19, 2, [2])\n",
      "(20, 2, [4])\n",
      "(21, 2, [5])\n",
      "(22, 2, [6, 14])\n",
      "(23, 2, [7])\n",
      "(24, 2, [8])\n",
      "(25, 2, [9])\n",
      "(26, 2, [10])\n",
      "(27, 2, [13])\n",
      "(28, 2, [15])\n",
      "(29, 2, [16])\n"
     ]
    }
   ],
   "source": [
    "# Dicion√°rio original\n",
    "array = {\n",
    "    0: {0: [0]},\n",
    "    1: {0: [1]},\n",
    "    2: {0: [2]},\n",
    "    3: {0: [3, 16]},\n",
    "    4: {0: [4], 1: [2], 2: [3]},\n",
    "    5: {0: [5]},\n",
    "    6: {0: [6, 8]},\n",
    "    7: {0: [7, 11]},\n",
    "    8: {0: [9]},\n",
    "    9: {0: [10]},\n",
    "    10: {0: [12]},\n",
    "    11: {0: [13], 2: [12]},\n",
    "    12: {0: [14], 2: [11]},\n",
    "    13: {0: [15]},\n",
    "    14: {1: [0]},\n",
    "    15: {1: [1]},\n",
    "    16: {1: [3]},\n",
    "    17: {2: [0]},\n",
    "    18: {2: [1]},\n",
    "    19: {2: [2]},\n",
    "    20: {2: [4]},\n",
    "    21: {2: [5]},\n",
    "    22: {2: [6, 14]},\n",
    "    23: {2: [7]},\n",
    "    24: {2: [8]},\n",
    "    25: {2: [9]},\n",
    "    26: {2: [10]},\n",
    "    27: {2: [13]},\n",
    "    28: {2: [15]},\n",
    "    29: {2: [16]},\n",
    "}\n",
    "\n",
    "# Transformando o dicion√°rio em uma lista de tuplas\n",
    "ii2 = [(k1, k2, v2) for k1, v1 in array.items() for k2, v2 in v1.items()]\n",
    "\n",
    "# Imprimindo a lista de tuplas\n",
    "for item in ii2:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = [\n",
    "    (0, 0, [1]),\n",
    "    (1, 0, [1]),\n",
    "    (2, 0, [2]),\n",
    "    (2, 1, [2]),\n",
    "    (2, 2, [2]),\n",
    "    (2, 3, [3]),\n",
    "    (3, 1, [1]),\n",
    "    (4, 1, [1]),\n",
    "    (5, 1, [2]),\n",
    "    (6, 1, [0]),\n",
    "    (7, 2, [0]),\n",
    "    (8, 2, [1]),\n",
    "    (9, 3, [1]),\n",
    "    (10, 3, [1]),\n",
    "    (11, 3, [2]),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentando de forma mais bonita:\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "def reconstruir_documento2(ii, vocab):\n",
    "    # Inicializando o documento como uma lista vazia\n",
    "    documento = []\n",
    "\n",
    "    # Iterando sobre cada entrada em 'ii'\n",
    "    for entry in ii:\n",
    "        # Desempacotando a entrada em √≠ndice de termo, √≠ndice de documento e posi√ß√µes\n",
    "        term_index, doc_index, positions = entry\n",
    "\n",
    "        # Encontrando o termo correspondente ao √≠ndice de termo no vocabul√°rio\n",
    "        term = list(vocab.keys())[list(vocab.values()).index(term_index)]\n",
    "\n",
    "        # Adicionando a tupla (termo, √≠ndice de documento, posi√ß√µes) ao documento\n",
    "        documento.append((term, doc_index, positions))\n",
    "\n",
    "    # Criando uma tabela bonita\n",
    "    table = PrettyTable()\n",
    "\n",
    "    # Definindo os cabe√ßalhos da tabela\n",
    "    table.field_names = [\"Termo\", \"√çndice do Documento\", \"Posi√ß√µes\"]\n",
    "\n",
    "    # Adicionando cada entrada do documento √† tabela\n",
    "    for term, doc_index, positions in documento:\n",
    "        table.add_row([term, doc_index, positions])\n",
    "\n",
    "    # Retornando a tabela como uma string\n",
    "    return str(table)\n",
    "\n",
    "\n",
    "def reconstruir_documento3(ii, vocab):\n",
    "    # Inicializando o documento como um dicion√°rio padr√£o\n",
    "    documento = defaultdict(list)\n",
    "\n",
    "    # Iterando sobre cada entrada em 'ii'\n",
    "    for entry in ii:\n",
    "        # Desempacotando a entrada em √≠ndice de termo, √≠ndice de documento e posi√ß√µes\n",
    "        term_index, doc_index, positions = entry\n",
    "\n",
    "        # Encontrando o termo correspondente ao √≠ndice de termo no vocabul√°rio\n",
    "        term = list(vocab.keys())[list(vocab.values()).index(term_index)]\n",
    "\n",
    "        # Adicionando a tupla (termo, posi√ß√µes) ao documento correspondente\n",
    "        documento[doc_index].append((term, positions))\n",
    "\n",
    "    # Imprimindo cada entrada do documento\n",
    "    for doc_index, entries in documento.items():\n",
    "        print(f\"Documento {doc_index}:\")\n",
    "        for term, positions in entries:\n",
    "            print(f\"  Termo: {term}, Posi√ß√µes: {positions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruir_documento(ii, vocab):\n",
    "    documento = []\n",
    "    for entry in ii:\n",
    "        term_index, doc_index, positions = entry\n",
    "        term = list(vocab.keys())[list(vocab.values()).index(term_index)]\n",
    "        documento.append((term, doc_index, positions))\n",
    "    return documento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('boa', 0, [1]), ('noite', 0, [1]), ('pessoal', 0, [2]), ('pessoal', 1, [2]), ('pessoal', 2, [2]), ('pessoal', 3, [3]), ('ja', 1, [1]), ('comecem', 1, [1]), ('0', 1, [2]), ('projeto', 1, [0]), ('alguma', 2, [0]), ('duvida', 2, [1]), ('isso', 3, [1]), ('e', 3, [1]), ('tudo', 3, [2])]\n"
     ]
    }
   ],
   "source": [
    "documento_reconstruido = reconstruir_documento(ii, VOCAB)\n",
    "print(documento_reconstruido)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cada', 0, [0]), ('qual', 0, [1]), ('sabe', 0, [2]), ('amar', 0, [3, 16]), ('a', 0, [4]), ('a', 1, [2]), ('a', 2, [3]), ('seu', 0, [5]), ('modo', 0, [6, 8]), ('o', 0, [7, 11]), ('pouco', 0, [9]), ('importa', 0, [10]), ('essencial', 0, [12]), ('e', 0, [13]), ('e', 2, [12]), ('que', 0, [14]), ('que', 2, [11]), ('saiba', 0, [15]), ('boa', 1, [0]), ('prova', 1, [1]), ('todos', 1, [3]), ('nao', 2, [0]), ('quero', 2, [1]), ('ter', 2, [2]), ('terrivel', 2, [4]), ('limitacao', 2, [5]), ('de', 2, [6, 14]), ('quem', 2, [7]), ('vive', 2, [8]), ('apenas', 2, [9]), ('do', 2, [10]), ('passivel', 2, [13]), ('fazer', 2, [15]), ('sentido', 2, [16])]\n"
     ]
    }
   ],
   "source": [
    "documento_reconstruido = reconstruir_documento(ii2, VOCAB2)\n",
    "print(documento_reconstruido)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------+----------+\n",
      "|   Termo   | √çndice do Documento | Posi√ß√µes |\n",
      "+-----------+---------------------+----------+\n",
      "|    cada   |          0          |   [0]    |\n",
      "|    qual   |          0          |   [1]    |\n",
      "|    sabe   |          0          |   [2]    |\n",
      "|    amar   |          0          | [3, 16]  |\n",
      "|     a     |          0          |   [4]    |\n",
      "|     a     |          1          |   [2]    |\n",
      "|     a     |          2          |   [3]    |\n",
      "|    seu    |          0          |   [5]    |\n",
      "|    modo   |          0          |  [6, 8]  |\n",
      "|     o     |          0          | [7, 11]  |\n",
      "|   pouco   |          0          |   [9]    |\n",
      "|  importa  |          0          |   [10]   |\n",
      "| essencial |          0          |   [12]   |\n",
      "|     e     |          0          |   [13]   |\n",
      "|     e     |          2          |   [12]   |\n",
      "|    que    |          0          |   [14]   |\n",
      "|    que    |          2          |   [11]   |\n",
      "|   saiba   |          0          |   [15]   |\n",
      "|    boa    |          1          |   [0]    |\n",
      "|   prova   |          1          |   [1]    |\n",
      "|   todos   |          1          |   [3]    |\n",
      "|    nao    |          2          |   [0]    |\n",
      "|   quero   |          2          |   [1]    |\n",
      "|    ter    |          2          |   [2]    |\n",
      "|  terrivel |          2          |   [4]    |\n",
      "| limitacao |          2          |   [5]    |\n",
      "|     de    |          2          | [6, 14]  |\n",
      "|    quem   |          2          |   [7]    |\n",
      "|    vive   |          2          |   [8]    |\n",
      "|   apenas  |          2          |   [9]    |\n",
      "|     do    |          2          |   [10]   |\n",
      "|  passivel |          2          |   [13]   |\n",
      "|   fazer   |          2          |   [15]   |\n",
      "|  sentido  |          2          |   [16]   |\n",
      "+-----------+---------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "documento_reconstruido = reconstruir_documento2(ii2, VOCAB2)\n",
    "print(documento_reconstruido)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irei indexar os documentos fornecidos e atualizar o vocabul√°rio existente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB2 =  {'cada': 0, 'qual': 1, 'sabe': 2, 'amar': 3, 'a': 4, 'seu': 5, 'modo': 6, 'o': 7, 'pouco': 8, 'importa': 9, 'essencial': 10, 'e': 11, 'que': 12, 'saiba': 13, 'boa': 14, 'prova': 15, 'todos': 16, 'nao': 17, 'quero': 18, 'ter': 19, 'terrivel': 20, 'limitacao': 21, 'de': 22, 'quem': 23, 'vive': 24, 'apenas': 25, 'do': 26, 'passivel': 27, 'fazer': 28, 'sentido': 29, 'ser': 30, 'ou': 31, 'n√£o': 32, 'eis': 33, 'quest√£o': 34, 'at√©': 35, 'tu': 36, 'brutus': 37, 'filho': 38, 'meu': 39}\n",
      "II2 =  {30: [(0, 0), (0, 3)], 31: [(0, 1)], 32: [(0, 2)], 33: [(0, 4)], 4: [(0, 5)], 34: [(0, 6)], 35: [(1, 0)], 36: [(1, 1)], 37: [(1, 2)], 38: [(1, 3)], 39: [(1, 4)]}\n"
     ]
    }
   ],
   "source": [
    "# Documentos a serem indexados\n",
    "documentos = [\"Ser ou n√£o ser, eis a quest√£o.\", \"At√© tu, Brutus, filho meu?\"]\n",
    "\n",
    "# Inicializando o √≠ndice invertido como um dicion√°rio padr√£o\n",
    "II2 = defaultdict(list)\n",
    "\n",
    "# Iterando sobre cada documento\n",
    "for doc_index, doc in enumerate(documentos):\n",
    "    # Dividindo o documento em palavras\n",
    "    palavras = doc.split()\n",
    "\n",
    "    # Iterando sobre cada palavra no documento\n",
    "    for pos, palavra in enumerate(palavras):\n",
    "        # Removendo a pontua√ß√£o e convertendo para min√∫sculas\n",
    "        palavra = palavra.strip(\",.!?\").lower()\n",
    "\n",
    "        # Se a palavra n√£o est√° no vocabul√°rio, adicione-a\n",
    "        if palavra not in VOCAB2:\n",
    "            VOCAB2[palavra] = len(VOCAB2)\n",
    "\n",
    "        # Adicionando a posi√ß√£o da palavra ao √≠ndice invertido\n",
    "        II2[VOCAB2[palavra]].append((doc_index, pos))\n",
    "\n",
    "# Imprimindo VOCAB2 e II2\n",
    "print(\"VOCAB2 = \", VOCAB2)\n",
    "print(\"II2 = \", dict(II2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irei criar uma representa√ß√£o da √°rvore de sintaxe e atribuir √≠ndices a cada n√≥ para a consulta fornecida. Aqui est√° o c√≥digo para construir essa √°rvore e os √≠ndices, onde o objetivo √© construir a √°rvore de sintaxe e os √≠ndices para a consulta pessoal AND (boa OR tudo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nodo:\n",
    "    def __init__(self, valor=None, esquerda=None, direita=None):\n",
    "        self.valor = valor\n",
    "        self.esquerda = esquerda\n",
    "        self.direita = direita\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_arvore_consulta():\n",
    "    # Criar os nodos para os termos da consulta\n",
    "    nodo_pessoal = Nodo(valor=\"pessoal\")\n",
    "    nodo_boa = Nodo(valor=\"boa\")\n",
    "    nodo_tudo = Nodo(valor=\"tudo\")\n",
    "\n",
    "    # Nodos para os operadores l√≥gicos\n",
    "    nodo_or = Nodo(valor=\"OR\", esquerda=nodo_boa, direita=nodo_tudo)\n",
    "    nodo_and = Nodo(valor=\"AND\", esquerda=nodo_pessoal, direita=nodo_or)\n",
    "\n",
    "    return nodo_and\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atribuir_indices_arvore(nodo, vocab):\n",
    "    indices = {}\n",
    "\n",
    "    # Percorrer a √°rvore em pr√©-ordem para atribuir √≠ndices aos termos\n",
    "    def percorrer_arvore(nodo):\n",
    "        nonlocal indices\n",
    "        if nodo is not None:\n",
    "            if nodo.valor in vocab:\n",
    "                indices[nodo.valor] = vocab[nodo.valor]\n",
    "            percorrer_arvore(nodo.esquerda)\n",
    "            percorrer_arvore(nodo.direita)\n",
    "\n",
    "    percorrer_arvore(nodo)\n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir a √°rvore para a consulta pessoal AND (boa OR tudo)\n",
    "arvore_consulta = construir_arvore_consulta()\n",
    "\n",
    "# Atribuir √≠ndices aos termos na √°rvore\n",
    "indices_arvore = atribuir_indices_arvore(arvore_consulta, VOCAB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "√çndices atribu√≠dos aos termos na √°rvore:\n",
      "{'pessoal': 2, 'boa': 0, 'tudo': 11}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n√çndices atribu√≠dos aos termos na √°rvore:\")\n",
    "print(indices_arvore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexar o documento \"Boatarde galera\"\n",
    "Para indexar o documento \"Boatarde galera\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexar_documento(documento, vocabulario):\n",
    "    palavras = documento.lower().split()\n",
    "    indice = []\n",
    "\n",
    "    for palavra in palavras:\n",
    "        if palavra in vocabulario:\n",
    "            indice.append(vocabulario[palavra])\n",
    "\n",
    "    return indice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√çndice do documento 'Boatarde galera': [0]\n"
     ]
    }
   ],
   "source": [
    "# Documento a ser indexado\n",
    "documento = \"Boa tarde galera\"\n",
    "\n",
    "# Indexar o documento usando o vocabul√°rio\n",
    "indice_l = indexar_documento(documento, VOCAB)\n",
    "\n",
    "print(\"√çndice do documento 'Boatarde galera':\", indice_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recupera√ß√£o de Documentos Relevantes\n",
    "Recuperar e Reconstruir documento(s) relevantes para a consulta \"Boa AND noite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperar_documentos_relevantes(consulta, ii):\n",
    "    relevantes = []\n",
    "    for term_index in consulta:\n",
    "        for entry in ii:\n",
    "            if entry[0] == term_index:\n",
    "                relevantes.append(entry)\n",
    "    return relevantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('alguma', 2, [0]), ('duvida', 2, [1])]\n"
     ]
    }
   ],
   "source": [
    "consulta = [(7), (8)]  # Boa AND noite\n",
    "documentos_relevantes = recuperar_documentos_relevantes(consulta, ii)\n",
    "documentos_relevantes_reconstruidos = reconstruir_documento(\n",
    "    documentos_relevantes, VOCAB\n",
    ")\n",
    "print(documentos_relevantes_reconstruidos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress√£o Est√°tica com C√≥digo de Huffman\n",
    "Para realizar a compress√£o est√°tica com o c√≥digo de Huffman:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodoHuffman:\n",
    "    def __init__(self, palavra=None, frequencia=0):\n",
    "        self.palavra = palavra\n",
    "        self.frequencia = frequencia\n",
    "        self.esquerda = None\n",
    "        self.direita = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_frequencias(texto):\n",
    "    frequencias = {}\n",
    "    palavras = texto.split()\n",
    "\n",
    "    for palavra in palavras:\n",
    "        if palavra in frequencias:\n",
    "            frequencias[palavra] += 1\n",
    "        else:\n",
    "            frequencias[palavra] = 1\n",
    "\n",
    "    return frequencias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_arvore_huffman(frequencias):\n",
    "    fila = [\n",
    "        NodoHuffman(palavra=palavra, frequencia=freq)\n",
    "        for palavra, freq in frequencias.items()\n",
    "    ]\n",
    "\n",
    "    while len(fila) > 1:\n",
    "        fila = sorted(fila, key=lambda x: x.frequencia)\n",
    "\n",
    "        esquerda = fila.pop(0)\n",
    "        direita = fila.pop(0)\n",
    "\n",
    "        pai = NodoHuffman(frequencia=esquerda.frequencia + direita.frequencia)\n",
    "        pai.esquerda = esquerda\n",
    "        pai.direita = direita\n",
    "\n",
    "        fila.append(pai)\n",
    "\n",
    "    return fila[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_tabela_codigos(nodo, codigo=\"\", tabela={}):\n",
    "    if nodo is not None:\n",
    "        if nodo.palavra is not None:\n",
    "            tabela[nodo.palavra] = codigo\n",
    "        construir_tabela_codigos(nodo.esquerda, codigo + \"0\", tabela)\n",
    "        construir_tabela_codigos(nodo.direita, codigo + \"1\", tabela)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codificar_texto(texto, tabela_codigos):\n",
    "    palavras = texto.split()\n",
    "    texto_codificado = \"\"\n",
    "\n",
    "    for palavra in palavras:\n",
    "        if palavra in tabela_codigos:\n",
    "            texto_codificado += (\n",
    "                tabela_codigos[palavra] + \" \"\n",
    "            )  # Adiciona o c√≥digo da palavra e um espa√ßo\n",
    "        else:\n",
    "            texto_codificado += (\n",
    "                palavra + \" \"\n",
    "            )  # Adiciona a palavra diretamente com um espa√ßo\n",
    "\n",
    "    return texto_codificado.strip()  # Remove o espa√ßo extra no final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodificar_texto(texto_codificado, tabela_codigos):\n",
    "    texto_decodificado = \"\"\n",
    "    codigos = texto_codificado.split()\n",
    "\n",
    "    for codigo in codigos:\n",
    "        palavra_decodificada = next(\n",
    "            (\n",
    "                palavra\n",
    "                for palavra, codigo_tabela in tabela_codigos.items()\n",
    "                if codigo_tabela == codigo\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if palavra_decodificada is not None:\n",
    "            texto_decodificado += (\n",
    "                palavra_decodificada + \" \"\n",
    "            )  # Adiciona a palavra decodificada ao texto\n",
    "\n",
    "    return texto_decodificado.strip()  # Remove o espa√ßo extra no final, se houver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o principal para compress√£o de texto usando Huffman com palavras\n",
    "def compressao_huffman(texto):\n",
    "    frequencias = calcular_frequencias(texto)\n",
    "    arvore_huffman = construir_arvore_huffman(frequencias)\n",
    "\n",
    "    tabela_codigos = {}\n",
    "    construir_tabela_codigos(arvore_huffman, \"\", tabela_codigos)\n",
    "\n",
    "    texto_codificado = codificar_texto(texto, tabela_codigos)\n",
    "\n",
    "    return texto_codificado, tabela_codigos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©todo baseado em Dicion√°rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso da compress√£o de Huffman com palavras\n",
    "texto_original = \"O tempo respondeu pro tempo que n√£o tem tempo pro tempo\"\n",
    "\n",
    "# Realiza a compress√£o usando Huffman com palavras\n",
    "texto_codificado, tabela_codigos = compressao_huffman(texto_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela de c√≥digos Huffman:\n",
      "O: 000\n",
      "respondeu: 001\n",
      "que: 010\n",
      "n√£o: 011\n",
      "tem: 100\n",
      "pro: 101\n",
      "tempo: 11\n",
      "Texto comprimido (em bin√°rio): 000 11 001 101 11 010 011 100 11 101 11\n",
      "Texto decodificado: O tempo respondeu pro tempo que n√£o tem tempo pro tempo\n",
      "Texto original    : O tempo respondeu pro tempo que n√£o tem tempo pro tempo\n"
     ]
    }
   ],
   "source": [
    "print(\"Tabela de c√≥digos Huffman:\")\n",
    "for palavra, codigo in tabela_codigos.items():\n",
    "    print(f\"{palavra}: {codigo}\")\n",
    "print(\"Texto comprimido (em bin√°rio):\", texto_codificado)\n",
    "\n",
    "# Decodifica o texto comprimido usando Huffman com palavras\n",
    "texto_decodificado = decodificar_texto(texto_codificado, tabela_codigos)\n",
    "print(\"Texto decodificado:\", texto_decodificado)\n",
    "print(\"Texto original    :\", texto_original)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta implementa√ß√£o:\n",
    "\n",
    " - A fun√ß√£o calcular_frequencias calcula as frequ√™ncias de cada caractere no texto.\n",
    " - A fun√ß√£o construir_arvore_huffman constr√≥i a √°rvore de Huffman com base nas frequ√™ncias calculadas.\n",
    " - A fun√ß√£o codificar_texto utiliza uma tabela de c√≥digos Huffman para codificar o texto original.\n",
    " - A fun√ß√£o decodificar_texto decodifica o texto comprimido usando a √°rvore de Huffman."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress√£o do Texto: \"Esperando a prova, sigo estudando para a prova\"\n",
    "Para aplicar a compress√£o baseada em dicion√°rio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressao_baseada_em_dicionario(texto, dicionario):\n",
    "    palavras = texto.lower().split()\n",
    "    texto_comprimido = []\n",
    "\n",
    "    for palavra in palavras:\n",
    "        if palavra in dicionario:\n",
    "            texto_comprimido.append(dicionario[palavra])\n",
    "        else:\n",
    "            texto_comprimido.append(\n",
    "                palavra\n",
    "            )  # Mant√©m a palavra se n√£o estiver no dicion√°rio\n",
    "\n",
    "    texto_comprimido = \" \".join(texto_comprimido)\n",
    "    return texto_comprimido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicion√°rio de substitui√ß√£o para compress√£o\n",
    "dicionario_compressao = {\n",
    "    \"esperando\": \"Esp\",\n",
    "    \"a\": \"a\",\n",
    "    \"prova\": \"P\",\n",
    "    \"sigo\": \"S\",\n",
    "    \"estudando\": \"E\",\n",
    "    \"para\": \"p\",\n",
    "    \"a\": \"a\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de texto para compress√£o\n",
    "texto_original = \"Esperando a prova, sigo estudando para a prova\"\n",
    "\n",
    "# Realiza a compress√£o baseada em dicion√°rio\n",
    "texto_comprimido = compressao_baseada_em_dicionario(\n",
    "    texto_original, dicionario_compressao\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: Esperando a prova, sigo estudando para a prova\n",
      "Texto comprimido: Esp a prova, S E p a P\n"
     ]
    }
   ],
   "source": [
    "print(\"Texto original:\", texto_original)\n",
    "print(\"Texto comprimido:\", texto_comprimido)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
