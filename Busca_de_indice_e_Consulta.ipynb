{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busca de Índice e Consulta de documento\n",
    "\n",
    "**Autor:** Davi J. Leite Santos  \n",
    "**Versão:** 0.0.3  \n",
    "**Data:** 25 de Abril de 2024  \n",
    "**Localização:** Ribeirão das Neves, Minas Gerais - Brasil  \n",
    "\n",
    "## Contato\n",
    "- 🏠 **Endereço:** Ribeirão das Neves, Minas Gerais - Brasil\n",
    "- 📧 **Email:** davi.jls@outlook.com\n",
    "- 🌐 **LinkedIn:** davi-j-leite-santos\n",
    "- 🌐 **Website:** davijls.com.br\n",
    "\n",
    "## Principais Competências\n",
    "- **Cibersegurança**\n",
    "- **Segurança da Informação**\n",
    "- **Operações de TI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruir o documento\n",
    "Para reconstruir o documento usando o índice invertido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = {\n",
    "    'boa': (0),\n",
    "    'noite': (1),\n",
    "    'pessoal': (2),\n",
    "    'ja': (3),\n",
    "    'comecem': (4),\n",
    "    '0': (5),\n",
    "    'projeto': (6),\n",
    "    'alguma': (7),\n",
    "    'duvida': (8),\n",
    "    'isso': (9),\n",
    "    'e': (10),\n",
    "    'tudo': (11)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = [\n",
    "    (0, 0, [1]), (1, 0, [1]), (2, 0, [2]),\n",
    "    (2, 1, [2]), (2, 2, [2]), (2, 3, [3]),\n",
    "    (3, 1, [1]), (4, 1, [1]), (5, 1, [2]),\n",
    "    (6, 1, [0]), (7, 2, [0]), (8, 2, [1]),\n",
    "    (9, 3, [1]), (10, 3, [1]), (11, 3, [2]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruir_documento(ii, vocab):\n",
    "    documento = []\n",
    "    for entry in ii:\n",
    "        term_index, doc_index, positions = entry\n",
    "        term = list(\n",
    "            vocab.keys()\n",
    "            )[list(\n",
    "                vocab.values()\n",
    "                ).index(term_index)]\n",
    "        documento.append((term, doc_index, positions))\n",
    "    return documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('boa', 0, [1]), ('noite', 0, [1]), ('pessoal', 0, [2]), ('pessoal', 1, [2]), ('pessoal', 2, [2]), ('pessoal', 3, [3]), ('ja', 1, [1]), ('comecem', 1, [1]), ('0', 1, [2]), ('projeto', 1, [0]), ('alguma', 2, [0]), ('duvida', 2, [1]), ('isso', 3, [1]), ('e', 3, [1]), ('tudo', 3, [2])]\n"
     ]
    }
   ],
   "source": [
    "documento_reconstruido = reconstruir_documento(ii, VOCAB)\n",
    "print(documento_reconstruido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irei criar uma representação da árvore de sintaxe e atribuir índices a cada nó para a consulta fornecida. Aqui está o código para construir essa árvore e os índices, onde o objetivo é construir a árvore de sintaxe e os índices para a consulta pessoal AND (boa OR tudo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nodo:\n",
    "    def __init__(self, valor=None, esquerda=None, direita=None):\n",
    "        self.valor = valor\n",
    "        self.esquerda = esquerda\n",
    "        self.direita = direita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_arvore_consulta():\n",
    "    # Criar os nodos para os termos da consulta\n",
    "    nodo_pessoal = Nodo(valor='pessoal')\n",
    "    nodo_boa = Nodo(valor='boa')\n",
    "    nodo_tudo = Nodo(valor='tudo')\n",
    "\n",
    "    # Nodos para os operadores lógicos\n",
    "    nodo_or = Nodo(valor='OR', esquerda=nodo_boa, direita=nodo_tudo)\n",
    "    nodo_and = Nodo(valor='AND', esquerda=nodo_pessoal, direita=nodo_or)\n",
    "\n",
    "    return nodo_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atribuir_indices_arvore(nodo, vocab):\n",
    "    indices = {}\n",
    "    # Percorrer a árvore em pré-ordem para atribuir índices aos termos\n",
    "    def percorrer_arvore(nodo):\n",
    "        nonlocal indices\n",
    "        if nodo is not None:\n",
    "            if nodo.valor in vocab:\n",
    "                indices[nodo.valor] = vocab[nodo.valor]\n",
    "            percorrer_arvore(nodo.esquerda)\n",
    "            percorrer_arvore(nodo.direita)\n",
    "\n",
    "    percorrer_arvore(nodo)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir a árvore para a consulta pessoal AND (boa OR tudo)\n",
    "arvore_consulta = construir_arvore_consulta()\n",
    "\n",
    "# Atribuir índices aos termos na árvore\n",
    "indices_arvore = atribuir_indices_arvore(arvore_consulta, VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Índices atribuídos aos termos na árvore:\n",
      "{'pessoal': 2, 'boa': 0, 'tudo': 11}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nÍndices atribuídos aos termos na árvore:\")\n",
    "print(indices_arvore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexar o documento \"Boatarde galera\"\n",
    "Para indexar o documento \"Boatarde galera\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexar_documento(documento, vocabulario):\n",
    "    palavras = documento.lower().split()\n",
    "    indice = []\n",
    "\n",
    "    for palavra in palavras:\n",
    "        if palavra in vocabulario:\n",
    "            indice.append(vocabulario[palavra])\n",
    "\n",
    "    return indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índice do documento 'Boatarde galera': [0]\n"
     ]
    }
   ],
   "source": [
    "# Documento a ser indexado\n",
    "documento = \"Boa tarde galera\"\n",
    "\n",
    "# Indexar o documento usando o vocabulário\n",
    "indice_l = indexar_documento(documento, VOCAB)\n",
    "\n",
    "print(\"Índice do documento 'Boatarde galera':\", indice_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recuperação de Documentos Relevantes\n",
    "Recuperar e Reconstruir documento(s) relevantes para a consulta \"Boa AND noite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperar_documentos_relevantes(consulta, ii):\n",
    "    relevantes = []\n",
    "    for term_index in consulta:\n",
    "        for entry in ii:\n",
    "            if entry[0] == term_index:\n",
    "                relevantes.append(entry)\n",
    "    return relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('boa', 0, [1]), ('noite', 0, [1])]\n"
     ]
    }
   ],
   "source": [
    "consulta = [(0), (1)]  # Boa AND noite\n",
    "documentos_relevantes = recuperar_documentos_relevantes(consulta, ii)\n",
    "documentos_relevantes_reconstruidos = reconstruir_documento(documentos_relevantes, VOCAB)\n",
    "print(documentos_relevantes_reconstruidos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressão Estática com Código de Huffman\n",
    "Para realizar a compressão estática com o código de Huffman:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodoHuffman:\n",
    "    def __init__(self, caractere=None, frequencia=0):\n",
    "        self.caractere = caractere\n",
    "        self.frequencia = frequencia\n",
    "        self.esquerda = None\n",
    "        self.direita = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_frequencias(texto):\n",
    "    frequencias = {}\n",
    "    for char in texto:\n",
    "        if char in frequencias:\n",
    "            frequencias[char] += 1\n",
    "        else:\n",
    "            frequencias[char] = 1\n",
    "    return frequencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_arvore_huffman(frequencias):\n",
    "    fila = [NodoHuffman(caractere=char, frequencia=freq) for char, freq in frequencias.items()]\n",
    "\n",
    "    while len(fila) > 1:\n",
    "        fila = sorted(fila, key=lambda x: x.frequencia)\n",
    "\n",
    "        esquerda = fila.pop(0)\n",
    "        direita = fila.pop(0)\n",
    "\n",
    "        pai = NodoHuffman(frequencia=esquerda.frequencia + direita.frequencia)\n",
    "        pai.esquerda = esquerda\n",
    "        pai.direita = direita\n",
    "\n",
    "        fila.append(pai)\n",
    "\n",
    "    return fila[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codificar_texto(texto, tabela_codigos):\n",
    "    texto_codificado = \"\"\n",
    "    for char in texto:\n",
    "        texto_codificado += tabela_codigos[char]\n",
    "    return texto_codificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodificar_texto(texto_codificado, arvore_huffman):\n",
    "    texto_decodificado = \"\"\n",
    "    nodo_atual = arvore_huffman\n",
    "\n",
    "    for bit in texto_codificado:\n",
    "        if bit == '0':\n",
    "            nodo_atual = nodo_atual.esquerda\n",
    "        else:\n",
    "            nodo_atual = nodo_atual.direita\n",
    "        \n",
    "        if nodo_atual.caractere is not None:\n",
    "            texto_decodificado += nodo_atual.caractere\n",
    "            nodo_atual = arvore_huffman\n",
    "    \n",
    "    return texto_decodificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função principal para compressão de texto usando Huffman\n",
    "def compressao_huffman(texto):\n",
    "    frequencias = calcular_frequencias(texto)\n",
    "    arvore_huffman = construir_arvore_huffman(frequencias)\n",
    "\n",
    "    tabela_codigos = {}\n",
    "    def construir_tabela_codigos(nodo, codigo=\"\"):\n",
    "        if nodo.caractere is not None:\n",
    "            tabela_codigos[nodo.caractere] = codigo\n",
    "        if nodo.esquerda:\n",
    "            construir_tabela_codigos(nodo.esquerda, codigo + \"0\")\n",
    "        if nodo.direita:\n",
    "            construir_tabela_codigos(nodo.direita, codigo + \"1\")\n",
    "    \n",
    "    construir_tabela_codigos(arvore_huffman)\n",
    "\n",
    "    texto_codificado = codificar_texto(texto, tabela_codigos)\n",
    "\n",
    "    return texto_codificado, arvore_huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import huffman\n",
    "\n",
    "# Exemplo de uso da compressão de Huffman\n",
    "texto_original = \"for my rose, a rose is a rose\"\n",
    "\n",
    "# Realiza a compressão usando Huffman\n",
    "texto_codificado, arvore_huffman = compressao_huffman(texto_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: for my rose, a rose is a rose\n",
      "Texto comprimido (em binário): 1110010010101111011111001101100110000111110100110110110011000001001011001001101101100110000\n",
      "Texto decodificado: for my rose, a rose is a rose\n"
     ]
    }
   ],
   "source": [
    "print(\"Texto original:\", texto_original)\n",
    "print(\"Texto comprimido (em binário):\", texto_codificado)\n",
    "\n",
    "# Decodifica o texto comprimido usando Huffman\n",
    "texto_decodificado = decodificar_texto(texto_codificado, arvore_huffman)\n",
    "print(\"Texto decodificado:\", texto_decodificado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta implementação:\n",
    "\n",
    " - A função calcular_frequencias calcula as frequências de cada caractere no texto.\n",
    " - A função construir_arvore_huffman constrói a árvore de Huffman com base nas frequências calculadas.\n",
    " - A função codificar_texto utiliza uma tabela de códigos Huffman para codificar o texto original.\n",
    " - A função decodificar_texto decodifica o texto comprimido usando a árvore de Huffman."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressão do Texto: \"Esperando a prova, sigo estudando para a prova\"\n",
    "Para aplicar a compressão baseada em dicionário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressao_baseada_em_dicionario(texto, dicionario):\n",
    "    palavras = texto.lower().split()\n",
    "    texto_comprimido = []\n",
    "\n",
    "    for palavra in palavras:\n",
    "        if palavra in dicionario:\n",
    "            texto_comprimido.append(dicionario[palavra])\n",
    "        else:\n",
    "            texto_comprimido.append(palavra)  # Mantém a palavra se não estiver no dicionário\n",
    "\n",
    "    texto_comprimido = \" \".join(texto_comprimido)\n",
    "    return texto_comprimido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário de substituição para compressão\n",
    "dicionario_compressao = {\n",
    "    \"esperando\": \"Esp\",\n",
    "    \"a\": \"a\",\n",
    "    \"prova\": \"P\",\n",
    "    \"sigo\": \"S\",\n",
    "    \"estudando\": \"E\",\n",
    "    \"para\": \"p\",\n",
    "    \"a\": \"a\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de texto para compressão\n",
    "texto_original = \"Esperando a prova, sigo estudando para a prova\"\n",
    "\n",
    "# Realiza a compressão baseada em dicionário\n",
    "texto_comprimido = compressao_baseada_em_dicionario(texto_original, dicionario_compressao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: Esperando a prova, sigo estudando para a prova\n",
      "Texto comprimido: Esp a prova, S E p a P\n"
     ]
    }
   ],
   "source": [
    "print(\"Texto original:\", texto_original)\n",
    "print(\"Texto comprimido:\", texto_comprimido)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
