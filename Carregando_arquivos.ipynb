{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busca de Índice e Consulta de documento\n",
    "\n",
    "**Autor:** Davi J. Leite Santos  \n",
    "**Versão:** 0.0.3  \n",
    "**Data:** 25 de Abril de 2024  \n",
    "**Localização:** Ribeirão das Neves, Minas Gerais - Brasil  \n",
    "\n",
    "## Contato\n",
    "- 🏠 **Endereço:** Ribeirão das Neves, Minas Gerais - Brasil\n",
    "- 📧 **Email:** davi.jls@outlook.com\n",
    "- 🌐 **LinkedIn:** davi-j-leite-santos\n",
    "- 🌐 **Website:** davijls.com.br\n",
    "\n",
    "## Principais Competências\n",
    "- **Cibersegurança**\n",
    "- **Segurança da Informação**\n",
    "- **Operações de TI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruir o documento\n",
    "Para reconstruir o documento usando o índice invertido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processo de carregar os arquivos e guarda-los\n",
    "\n",
    "Essa parte server para acessar cada documento e fazer o indice invertido de cada um, justamente para armazena-los de alguma forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo e processando os arquivos\n",
    "def process_file(file_path, vocab, index, doc_id):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File {file_path} does not exist.\")\n",
    "        return\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        words = f.read().split()\n",
    "    for pos, word in enumerate(words):\n",
    "        word = word.lower().strip(\".,!?;\")\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "        word_id = vocab[word]\n",
    "        if word_id not in index:\n",
    "            index[word_id] = {}\n",
    "        if doc_id not in index[word_id]:\n",
    "            index[word_id][doc_id] = []\n",
    "        index[word_id][doc_id].append(pos)\n",
    "\n",
    "# Salvando os index do indice invertido\n",
    "def save_index(vocab, index, vocab_file, index_file):\n",
    "    with open(vocab_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(vocab, f)\n",
    "    with open(index_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(index, f)\n",
    "\n",
    "#Lendo o progresso dos arquivos\n",
    "def load_progress(progress_file):\n",
    "    if os.path.exists(progress_file) and os.path.getsize(progress_file) > 0:\n",
    "        with open(progress_file, 'r', encoding='utf-8') as f:\n",
    "            progress = json.load(f)\n",
    "    else:\n",
    "        progress = {'last_processed': -1}\n",
    "    return progress\n",
    "\n",
    "# Salvando o progresso de analise dos arquivos para saber onde parou caso o codigo de algum bug e pare\n",
    "def save_progress(progress, progress_file):\n",
    "    with open(progress_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(progress, f)\n",
    "\n",
    "# Criando o indice invertido \n",
    "def create_inverted_index(files_dir, index_dir, vocab_dir, progress_file):\n",
    "    # Dando Load no progresso\n",
    "    progress = load_progress(progress_file)\n",
    "    \n",
    "    # Para ler cada arquivo com base no progresso\n",
    "    files = sorted(os.listdir(files_dir))\n",
    "    for i, file_name in enumerate(files):\n",
    "        if i <= progress['last_processed']:\n",
    "            continue\n",
    "        file_path = os.path.join(files_dir, file_name)\n",
    "        \n",
    "        # Criando os indices\n",
    "        vocab = {}\n",
    "        index = {}\n",
    "        process_file(file_path, vocab, index, 0)\n",
    "        \n",
    "        # Salvando em formato de arquivo\n",
    "        vocab_file = os.path.join(vocab_dir, f'vocab{i+1}.json')\n",
    "        index_file = os.path.join(index_dir, f'index{i+1}.json')\n",
    "        save_index(vocab, index, vocab_file, index_file)\n",
    "        \n",
    "        # Salvando o progresso\n",
    "        progress['last_processed'] = i\n",
    "        save_progress(progress, progress_file)\n",
    "        \n",
    "        print(f'Processed {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para juntar todos indices (Vocab e Index)\n",
    "def merge_indices_and_vocabs(index_dir, vocab_dir, index_geral_file, vocab_geral_file):\n",
    "    geral_index = {}\n",
    "    geral_vocab = {}\n",
    "    current_word_id = 0\n",
    "    \n",
    "    # Organizando os arquivos\n",
    "    index_files = sorted(os.listdir(index_dir))\n",
    "    vocab_files = sorted(os.listdir(vocab_dir))\n",
    "    \n",
    "    # Carregando esses arquivos\n",
    "    for index_file, vocab_file in zip(index_files, vocab_files):\n",
    "        with open(os.path.join(index_dir, index_file), 'r', encoding='utf-8') as f:\n",
    "            index = json.load(f)\n",
    "        with open(os.path.join(vocab_dir, vocab_file), 'r', encoding='utf-8') as f:\n",
    "            vocab = json.load(f)\n",
    "        \n",
    "        # Criando o indice invertido em apenas um arquivo\n",
    "        for word, word_id in vocab.items():\n",
    "            if word not in geral_vocab:\n",
    "                geral_vocab[word] = current_word_id\n",
    "                current_word_id += 1\n",
    "            geral_word_id = geral_vocab[word]\n",
    "            \n",
    "            if geral_word_id not in geral_index:\n",
    "                geral_index[geral_word_id] = {}\n",
    "            for doc_id, positions in index[str(word_id)].items():\n",
    "                doc_id = int(doc_id)\n",
    "                if doc_id not in geral_index[geral_word_id]:\n",
    "                    geral_index[geral_word_id][doc_id] = []\n",
    "                geral_index[geral_word_id][doc_id].extend(positions)\n",
    "    \n",
    "    # salvando esse indice maior em dois arquivos diferentes\n",
    "    with open(vocab_geral_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(geral_vocab, f)\n",
    "    with open(index_geral_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(geral_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina os caminhos dos diretórios e arquivos\n",
    "files_dir = '../Motor_de_busca-WebCrawler/sites_visitados'\n",
    "index_dir = 'indexs'\n",
    "vocab_dir = 'vocabs'\n",
    "progress_file = 'progress.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie os diretórios se não existirem\n",
    "os.makedirs(index_dir, exist_ok=True)\n",
    "os.makedirs(vocab_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie o índice invertido\n",
    "#create_inverted_index(files_dir, index_dir, vocab_dir, progress_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina os caminhos dos arquivos gerais\n",
    "index_geral_file = 'index_geral.json'\n",
    "vocab_geral_file = 'vocab_geral.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesclar os índices e vocabulários individuais nos arquivos gerais\n",
    "#merge_indices_and_vocabs(index_dir, vocab_dir, index_geral_file, vocab_geral_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazendo as leituras das operações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list_format(index_geral_file, list_geral_file):\n",
    "    with open(index_geral_file, 'r', encoding='utf-8') as f:\n",
    "        index = json.load(f)\n",
    "    \n",
    "    list_format = []\n",
    "    for word_id, docs in index.items():\n",
    "        for doc_id, positions in docs.items():\n",
    "            list_format.append({\n",
    "                'word_id': int(word_id),\n",
    "                'doc_id': doc_id,\n",
    "                'positions': positions\n",
    "            })\n",
    "    \n",
    "    with open(list_geral_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(list_format, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o caminho do arquivo de lista geral\n",
    "list_geral_file = 'list_geral.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converta o índice geral para o formato de lista\n",
    "convert_to_list_format(index_geral_file, list_geral_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_geral_files(index_geral_file, vocab_geral_file, list_geral_file):\n",
    "    with open(index_geral_file, 'r', encoding='utf-8') as f:\n",
    "        index_geral = json.load(f)\n",
    "    with open(vocab_geral_file, 'r', encoding='utf-8') as f:\n",
    "        vocab_geral = json.load(f)\n",
    "    with open(list_geral_file, 'r', encoding='utf-8') as f:\n",
    "        list_geral = json.load(f)\n",
    "    \n",
    "    return index_geral, vocab_geral, list_geral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os arquivos gerais\n",
    "index_geral, vocab_geral, list_geral = load_geral_files(index_geral_file, vocab_geral_file, list_geral_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tuple_format(index_geral_file, tuple_format_file):\n",
    "    with open(index_geral_file, 'r', encoding='utf-8') as f:\n",
    "        index = json.load(f)\n",
    "    \n",
    "    tuple_format = []\n",
    "    for word_id, docs in index.items():\n",
    "        for doc_id, positions in docs.items():\n",
    "            tuple_format.append((int(word_id), int(doc_id), positions))\n",
    "    \n",
    "    with open(tuple_format_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(tuple_format, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o caminho do arquivo de formato de tupla\n",
    "tuple_format_file = 'tuple_format.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converta o índice geral para o formato de tupla\n",
    "convert_to_tuple_format(index_geral_file, tuple_format_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_all_files2(index_geral_file, vocab_geral_file, tuple_format_file):\n",
    "    with open(index_geral_file, 'r', encoding='utf-8') as f:\n",
    "        index_geral = json.load(f)\n",
    "    with open(vocab_geral_file, 'r', encoding='utf-8') as f:\n",
    "        vocab_geral = json.load(f)\n",
    "    with open(tuple_format_file, 'r', encoding='utf-8') as f:\n",
    "        tuple_format = json.load(f)\n",
    "    \n",
    "    return index_geral, vocab_geral, tuple_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os arquivos gerais e o arquivo de formato de tupla\n",
    "index_geral, vocab_geral, tuple_format = load_all_files2(index_geral_file, vocab_geral_file, tuple_format_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variaveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de como usar os dados carregados\n",
    "#print(\"Índice Geral:\", index_geral)\n",
    "#print(\"Vocabulário Geral:\", vocab_geral)\n",
    "#print(\"Lista Geral:\", list_geral)\n",
    "#print(\"Formato de Tupla:\", tuple_format)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
